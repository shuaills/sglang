model:
  target:
    pretrained_model_name_or_path: meta-llama/Meta-Llama-3-8B-Instruct
  draft:
    type: LlamaForCausalLMEagle3

criterion:
  type: SmoothL1Loss
  reduction: none

optimizer:
  type: AdamW
  lr: 1e-4
  weight_decay: 0.01

data:
  train:
    path: /home/lyh/code/nlp/developing/vllmbase/vllm/gedata/l318b.jsonl
    batch_size: 8
  test_data:
    path: /home/lyh/code/nlp/developing/vllmbase/vllm/gedata/0318.json
    batch_size: 8

train:
  num_epochs: 40
  num_workers: 2
  max_len: 2048
  
